# 进程管理
## 进程与线程
1. 进程
进程是资源分配的基本单位。

进程控制块（PCB）描述进程的基本信息和运行状态，分配的资源包括内存空间、I/O设备等。

2. 线程
线程是独立调度的基本单位。

一个进程中可以有多个线程，它们共享进程资源。

3. 区别
* 拥有资源
进程是资源分配的基本单位，而线程不拥有资源，线程可以访问隶属进程的资源。

* 调度
线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，而不同进程中的线程切换，则会引起进程的切换。

* 系统开销
由于创建或撤销进程时，系统都要为他分配或回收资源，所付出的开销远大于创建或撤销线程时的开销。线程切换时只需保存或设置少量寄存器的内容，开销远小于进程切换。

* 通信
线程间可以直接读写同一进程中的数据进行通信，但进程通信需要借助IPC（进程间通信）。

## 进程状态的切换
进程有这三种状态：
* 就绪状态：等待被调度
* 运行状态
* 阻塞状态：等待资源

只有就绪态和运行态可以相互转换，其他的都是单向转换。例如，运行态等待I/O进入阻塞态，阻塞态I/O完成进入就绪态。

就绪状态的进程通过调度算法从而获得CPU时间，转为运行状态；而运行状态的进程，在分配给他的CPU时间片用完之后就会转为就绪状态，等待下一次调度。

## 调度算法
就交互式系统而言，有大量的用户操作，在该系统中调度算法的目标是快速的进行响应。

1. 时间片轮转
将所有就绪进程按FCFS（先来先服务）的原则排成一个队列，每次调度时，把CPU时间分配给队首进程，该进程执行一个时间片。当时间片用完，计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把CPU时间分配给队首的进程。

效率主要与时间片分配的大小有关。

2. 优先级调度
为每个进程分配一个优先级，按优先级进行调度。可以随着时间的推移增加等待进程的优先级。

3. 多级反馈队列
上面两种算法的结合，设置多个队列，从上往下，优先级依次下降，时间片逐渐增多。执行时，从上往下依次执行。

## 进程同步
1. 临界区
把对共享内存进行访问的程序片段称为临界区域，通过适当安排，使得两个进程不可能同时出于临界区中，就能够避免竞争条件。

2. 同步与互斥
* 同步：多个进程因为合作产生直接制约关系，使得进程有一定的先后执行关系。
* 互斥：多个进程在同一时刻只有一个进程能进入临界区。

3. 信号量
信号量是一个整型变量，可以对其进行常见的P和V操作，P表示占有，V表示释放。

这两种操作要被设计成原语，即不可分割的操作。通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量只能为0或者1，就称为互斥量（Mutex），0表示临界区已经加锁，1表示临界区解锁。

4. 管程
便于客户端调用，不需要做很多操作。

## 进程通信
进程同步与进程通信的区别在于：
* 进程同步：控制多个进程按一定顺序执行；
* 进程通信：进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。可以通过进程通信的方法来达到进程同步的目的。

1. 管道
通过调用pipe函数创建的。具有以下限制：
* 只支持半双工通信（单向交替传输）；
* 只能在父子进程或者兄弟进程中使用。

2. 命名管道（FIFO）
去除了管道只能用在父子进程中使用的限制。

3. 消息队列
可以独立于读写进程存在，避免了FIFO的同步阻塞问题，不需要进程自己提供同步方法。

读进程可以根据消息类型有选择地接受信息，而不像FIFO只能默认的接收。

4. 信号量
计数器，用于为多个进程提供对共享数据对象的访问。

5. 共享内存
允许多个进程共享一个给定的内存，数据不需要在进程之间复制，所以是最快的一种IPC。

6. 套接字
用于不同机器间的进程通信。

# 死锁
## 必要条件
* 互斥：资源不能共享，只能一个进程用。
* 占有和等待：已经得到资源的进程可以再请求新的资源。
* 不可抢占：已经分配的资源不能被强制性的抢占，只能被占有它的进程显式的释放。
* 环路等待：若干进程形成环路，环路中的每个进程都在等待下一个进程所占有的资源。

## 处理方法
死锁预防：破坏死锁四个产生条件中的一个，会影响到资源利用率和吞吐量。
死锁避免：在资源的动态分配中，在程序运行中避免发生死锁。
死锁检测：死锁发生后，通过算法进行检测，并清除死锁。
死锁解除：对死锁相关进程，通过撤销或挂起的方式，释放一些资源。

# 内存管理
## 虚拟内存
虚拟内存的目的是为了将物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

操作系统将内存抽象成地址空间，每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要将所有页都装入在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

虚拟内存使得有效的内存运行大程序成为可能。

## 分页系统地址映射
内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（page table）储存着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两部分，一部分储存页面号，一部分储存偏移量。

## 页面置换算法
当发生缺页中断时，就需要将该页调入内存中。如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

算法的主要目标是使页面置换频率最低，即缺页率最低。

1. LRU（最近最少使用）
维护一个所有页面的链表，当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

2. FIFO（先进先出）
选择换出的页面是最先进入的页面，可能会将经常被访问的页面换出，导致缺页率升高。

## 分段
虚拟内存采用的是分页技术，也就是将地址空间划分为固定大小的页，每一页再与内存进行映射。

如果程序使用的表是动态增长的话，会导致覆盖问题的出现。

分段的做法是将每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，可以动态增长。

## 段页式
程序的地址空间划分为多个拥有独立地址空间的段，每个段上的地址空间划分为大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

## 分页和分段的比较
* 分页对程序员来说是透明的，但是分段需要显式划分每个段；
* 分页是一维地址空间，分段是二维的；
* 页的大小不可变，段的大小可以动态改变；
* 分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间，有助于共享和保护。

# 堆与栈
## 堆
向上生长，需要程序员自己申请并指明大小。堆里的内存是不连续的，操作系统又记录空闲内存地址的链表，申请内存时遍历链表，找第一个空间大于申请空间的堆节点，分配内存。

## 栈
先进后出，向下生长，系统自动分配回收，高效快速，但有限制，数据不够灵活。申请内存时，只要栈的剩余空间大于所申请的空间，系统将为程序员提供内存，否则报栈溢出。